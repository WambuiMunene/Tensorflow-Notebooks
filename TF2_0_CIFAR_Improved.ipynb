{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaCbcuxT6BbbXcj/j/1tCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WambuiMunene/Tensorflow-Notebooks/blob/main/TF2_0_CIFAR_Improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TdXGczzCYj3v"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout,MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n"
      ],
      "metadata": {
        "id": "7FXFa7D_Y3ZV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "y_train, Y_test = y_train.flatten(),y_test.flatten()\n",
        "print(\"x_train.shape:\", x_train.shape)\n",
        "print(\"y_train,shape:\",y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSluCEdmZu2R",
        "outputId": "a565591d-6597-4f4f-b0cd-325c86d5d549"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (50000, 32, 32, 3)\n",
            "y_train,shape: (50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the number of classes\n",
        "\n",
        "K= len(set(y_train))\n",
        "print(\"Number of classes:\", K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDI-j7n0apAt",
        "outputId": "518877d4-e259-46ad-c1fb-25a3ca666239"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "LgPCKgnNa60V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using  the functional API\n",
        "i = Input(shape = x_train[0].shape)\n",
        "\n",
        "# data augmentation\n",
        "\n",
        "x = data_augmentation(i)  # the api willonly work on the train data\n",
        "\n",
        "# other layers\n",
        "x = Conv2D(32, (3,3), activation='relu', padding = 'same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(32, (3,3), activation='relu',padding = 'same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = MaxPooling2D((2,2)) (x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = MaxPooling2D((2,2)) (x)\n",
        "x = Conv2D(128, (3,3), activation='relu', padding='same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(128, (3,3), activation='relu', padding='same') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = MaxPooling2D((2,2)) (x)\n",
        "\n",
        "x = Flatten() (x)\n",
        "x = Dropout(0.2) (x)\n",
        "x = Dense(1024, activation = 'relu') (x)\n",
        "x = Dropout(0.2) (x)\n",
        "x = Dense(K,activation = 'softmax') (x)\n",
        "\n",
        "model = Model(i, x)\n"
      ],
      "metadata": {
        "id": "FMMoybKFboiW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Compile\n",
        "\n",
        " model.compile(optimizer = 'adam',\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "qVWt8Z-0mK9E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit with data augmentation (batchsize default is 32)\n",
        "r = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P00lTo4pmlTk",
        "outputId": "006abbb1-0cef-4f71-d89f-67f62d9d54a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 17ms/step - accuracy: 0.3852 - loss: 1.9253 - val_accuracy: 0.5127 - val_loss: 1.4059\n",
            "Epoch 2/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.5603 - loss: 1.2414 - val_accuracy: 0.6035 - val_loss: 1.1623\n",
            "Epoch 3/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6354 - loss: 1.0527 - val_accuracy: 0.6919 - val_loss: 0.8981\n",
            "Epoch 4/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6739 - loss: 0.9502 - val_accuracy: 0.7069 - val_loss: 0.8689\n",
            "Epoch 5/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6996 - loss: 0.8695 - val_accuracy: 0.7344 - val_loss: 0.7891\n",
            "Epoch 6/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7201 - loss: 0.8189 - val_accuracy: 0.7433 - val_loss: 0.7751\n",
            "Epoch 7/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7404 - loss: 0.7610 - val_accuracy: 0.7592 - val_loss: 0.7180\n",
            "Epoch 8/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.7504 - loss: 0.7259 - val_accuracy: 0.7233 - val_loss: 0.8482\n",
            "Epoch 9/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.7629 - loss: 0.6866 - val_accuracy: 0.7747 - val_loss: 0.6752\n",
            "Epoch 10/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.7720 - loss: 0.6597 - val_accuracy: 0.7731 - val_loss: 0.6631\n",
            "Epoch 11/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7809 - loss: 0.6284 - val_accuracy: 0.7752 - val_loss: 0.6785\n",
            "Epoch 12/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7965 - loss: 0.5938 - val_accuracy: 0.7943 - val_loss: 0.6185\n",
            "Epoch 13/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8019 - loss: 0.5783 - val_accuracy: 0.7514 - val_loss: 0.7509\n",
            "Epoch 14/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8083 - loss: 0.5506 - val_accuracy: 0.8016 - val_loss: 0.5905\n",
            "Epoch 15/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8126 - loss: 0.5420 - val_accuracy: 0.8082 - val_loss: 0.5802\n",
            "Epoch 16/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.8202 - loss: 0.5239 - val_accuracy: 0.7969 - val_loss: 0.6188\n",
            "Epoch 17/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8253 - loss: 0.5083 - val_accuracy: 0.8016 - val_loss: 0.6021\n",
            "Epoch 18/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8307 - loss: 0.4929 - val_accuracy: 0.8237 - val_loss: 0.5241\n",
            "Epoch 19/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8360 - loss: 0.4775 - val_accuracy: 0.8179 - val_loss: 0.5448\n",
            "Epoch 20/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8380 - loss: 0.4688 - val_accuracy: 0.8118 - val_loss: 0.5713\n",
            "Epoch 21/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8443 - loss: 0.4535 - val_accuracy: 0.8223 - val_loss: 0.5465\n",
            "Epoch 22/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8478 - loss: 0.4460 - val_accuracy: 0.8216 - val_loss: 0.5383\n",
            "Epoch 23/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8470 - loss: 0.4423 - val_accuracy: 0.8300 - val_loss: 0.5205\n",
            "Epoch 24/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8514 - loss: 0.4278 - val_accuracy: 0.8218 - val_loss: 0.5316\n",
            "Epoch 25/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8563 - loss: 0.4129 - val_accuracy: 0.8148 - val_loss: 0.5882\n",
            "Epoch 26/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8561 - loss: 0.4127 - val_accuracy: 0.8376 - val_loss: 0.5033\n",
            "Epoch 27/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8578 - loss: 0.4051 - val_accuracy: 0.8117 - val_loss: 0.5881\n",
            "Epoch 28/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8661 - loss: 0.3869 - val_accuracy: 0.8465 - val_loss: 0.4904\n",
            "Epoch 29/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8697 - loss: 0.3737 - val_accuracy: 0.8421 - val_loss: 0.4830\n",
            "Epoch 30/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8700 - loss: 0.3851 - val_accuracy: 0.8278 - val_loss: 0.5351\n",
            "Epoch 31/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8737 - loss: 0.3647 - val_accuracy: 0.8400 - val_loss: 0.5288\n",
            "Epoch 32/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.8696 - loss: 0.3754 - val_accuracy: 0.8586 - val_loss: 0.4366\n",
            "Epoch 33/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8753 - loss: 0.3612 - val_accuracy: 0.8366 - val_loss: 0.5053\n",
            "Epoch 34/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8771 - loss: 0.3502 - val_accuracy: 0.8443 - val_loss: 0.4626\n",
            "Epoch 35/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8804 - loss: 0.3451 - val_accuracy: 0.8388 - val_loss: 0.5231\n",
            "Epoch 36/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8818 - loss: 0.3370 - val_accuracy: 0.8550 - val_loss: 0.4322\n",
            "Epoch 37/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8871 - loss: 0.3258 - val_accuracy: 0.8519 - val_loss: 0.4589\n",
            "Epoch 38/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8867 - loss: 0.3315 - val_accuracy: 0.8335 - val_loss: 0.5205\n",
            "Epoch 39/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8909 - loss: 0.3278 - val_accuracy: 0.8381 - val_loss: 0.5164\n",
            "Epoch 40/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8885 - loss: 0.3221 - val_accuracy: 0.8558 - val_loss: 0.4447\n",
            "Epoch 41/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8906 - loss: 0.3167 - val_accuracy: 0.8565 - val_loss: 0.4477\n",
            "Epoch 42/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8891 - loss: 0.3155 - val_accuracy: 0.8611 - val_loss: 0.4370\n",
            "Epoch 43/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8951 - loss: 0.3046 - val_accuracy: 0.8430 - val_loss: 0.4985\n",
            "Epoch 44/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8927 - loss: 0.3075 - val_accuracy: 0.8611 - val_loss: 0.4541\n",
            "Epoch 45/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8958 - loss: 0.3066 - val_accuracy: 0.8506 - val_loss: 0.4468\n",
            "Epoch 46/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8971 - loss: 0.2965 - val_accuracy: 0.8565 - val_loss: 0.4493\n",
            "Epoch 47/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.8985 - loss: 0.2971 - val_accuracy: 0.8582 - val_loss: 0.4444\n",
            "Epoch 48/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.9015 - loss: 0.2880 - val_accuracy: 0.8576 - val_loss: 0.4546\n",
            "Epoch 49/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.9015 - loss: 0.2892 - val_accuracy: 0.8550 - val_loss: 0.4663\n",
            "Epoch 50/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.9022 - loss: 0.2861 - val_accuracy: 0.8413 - val_loss: 0.5586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G7zuzJO27L1",
        "outputId": "23f985f6-dcd3-45da-9a7f-5fafcdcb2140"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.5662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5586481094360352, 0.8413000106811523]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GGXpNWAhdFdN"
      }
    }
  ]
}