{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNF4x/ELIjPNLK/lA29qxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WambuiMunene/Tensorflow-Notebooks/blob/main/TF2_0_Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt8ip7-O5JeP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "mykBD0m65Pdz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n"
      ],
      "metadata": {
        "id": "m6jXjWtb8_7t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tiny dataset\n",
        "sentences = [\n",
        "    'I like eggs and ham',\n",
        "    'I love chocolate and bunnies',\n",
        "    'I hate onions'\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "KPd6hOXD9Mpc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 20000\n"
      ],
      "metadata": {
        "id": "zoB74CQu9run"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer = TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    # standardize = \"lower_and_strip_punctuation\",\n",
        "    # split = \"whitespace\",\n",
        "    # ngrams = None,\n",
        "    # output_mode='int',\n",
        ")"
      ],
      "metadata": {
        "id": "XQpEX00Y99XA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer.adapt(sentences)  # this is like the fit phase"
      ],
      "metadata": {
        "id": "BPLkK8VZ-xf6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = vectorization_layer(sentences)  # this is like the predict phase\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVm6gn7Y-78n",
        "outputId": "29ec89ed-5677-4d7f-b405-b79e98809e58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6  9  3  8]\n",
            " [ 2  5 10  3 11]\n",
            " [ 2  7  4  0  0]], shape=(3, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorization_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcdIyO_P_v3k",
        "outputId": "8dd9772c-652e-4153-fe79-baed64f1a7eb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('i'),\n",
              " np.str_('and'),\n",
              " np.str_('onions'),\n",
              " np.str_('love'),\n",
              " np.str_('like'),\n",
              " np.str_('hate'),\n",
              " np.str_('ham'),\n",
              " np.str_('eggs'),\n",
              " np.str_('chocolate'),\n",
              " np.str_('bunnies')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how do weget the word toindex mapping?\n",
        "word2idx ={v:k for k,v in enumerate(vectorization_layer.get_vocabulary())}\n",
        "print(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyAdxwRd_-Ce",
        "outputId": "754f9148-43e4-47d3-ee14-07964d441519"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'': 0, '[UNK]': 1, np.str_('i'): 2, np.str_('and'): 3, np.str_('onions'): 4, np.str_('love'): 5, np.str_('like'): 6, np.str_('hate'): 7, np.str_('ham'): 8, np.str_('eggs'): 9, np.str_('chocolate'): 10, np.str_('bunnies'): 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncation\n",
        "vectorization_layer_truncated =TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    output_sequence_length=3\n",
        "\n",
        ")\n",
        "\n",
        "#fit\n",
        "vectorization_layer_truncated.adapt(sentences)\n",
        "\n",
        "#vectorize\n",
        "sequences_truncated = vectorization_layer_truncated(sentences)\n",
        "print(sequences_truncated)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l23KRMWKHcmt",
        "outputId": "f21cd65f-1603-4bad-be49-c9b3badf8c93"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 2  6  9]\n",
            " [ 2  5 10]\n",
            " [ 2  7  4]], shape=(3, 3), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ragged (no padding) (TF backend only)\n",
        "vectorization_layer_ragged =TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    ragged = True\n",
        "\n",
        ")\n",
        "\n",
        "# fit\n",
        "vectorization_layer_ragged.adapt(sentences)\n",
        "\n",
        "# predict\n",
        "sequences_ragged = vectorization_layer_ragged(sentences)\n",
        "print(sequences_ragged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shfuw0ovIraU",
        "outputId": "beb716ac-a2b0-4c23-ef55-dc2bc76dd52b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[2, 6, 9, 3, 8], [2, 5, 10, 3, 11], [2, 7, 4]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences_ragged.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdaVJESTK07k",
        "outputId": "604a5c82-a502-4eb6-b7fd-46efe5ce876f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 6, 9, 3, 8], [2, 5, 10, 3, 11], [2, 7, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padat front instead of back\n",
        "# not supported in Text Vectorization layer itself\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "print(pad_sequences(sequences,padding='post'))\n",
        "\n",
        "#defaults:\n",
        "# tf.keras.utils.pad_sequences(\n",
        "#     sequences,\n",
        "#     maxlen=None,\n",
        "#     dtype='int32',\n",
        "#     padding='pre',\n",
        "#     truncating='pre',\n",
        "#     value=0.0\n",
        "# )\n",
        "\n",
        "padded = pad_sequences(sequences_ragged.to_list())\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6NvrXeKIz_F",
        "outputId": "90adcf29-9f06-4917-84dc-63ed996ae1ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  6  9  3  8]\n",
            " [ 2  5 10  3 11]\n",
            " [ 2  7  4  0  0]]\n",
            "[[ 2  6  9  3  8]\n",
            " [ 2  5 10  3 11]\n",
            " [ 0  0  2  7  4]]\n"
          ]
        }
      ]
    }
  ]
}